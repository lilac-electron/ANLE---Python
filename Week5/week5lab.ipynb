{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Sentence Completion Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will load the language_model class (developed last week) and train it using the files in the training directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "There are 522 files in the training directory: /Users/finpearson/Desktop/Github/ANLE---Python-/Week4/sentence-completion/Holmes_Training_Data\n",
      "Processing 19TOM10.TXT\n",
      "Processing SNOWI10.TXT\n",
      "Processing FBRLS10.TXT\n",
      "Processing WTSLW10.TXT\n",
      "UnicodeDecodeError processing WTSLW10.TXT: ignoring rest of file\n",
      "Processing MOHIC10.TXT\n",
      "UnicodeDecodeError processing MOHIC10.TXT: ignoring rest of file\n",
      "Processing CEVEN10.TXT\n",
      "Processing WNLAW10.TXT\n",
      "Processing PRESC10.TXT\n",
      "Processing MPOOL10.TXT\n",
      "Processing AHERO10.TXT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "#this means that language_model will be reloaded when you run this cell - this is important if you change the language_model class!\n",
    "import os\n",
    "from language_model import * \n",
    "## import language model from previous lab\n",
    "parentdir=\"/Users/finpearson/Desktop/Github/ANLE---Python-/Week4/sentence-completion/\" \n",
    "#you may need to update this \n",
    "\n",
    "trainingdir=os.path.join(parentdir,\"Holmes_Training_Data\")\n",
    "training,testing=get_training_testing(trainingdir)\n",
    "MAX_FILES=10  \n",
    "\n",
    " #use a small number here whilst developing your solutions\n",
    "mylm=language_model(trainingdir=trainingdir,files=training[:MAX_FILES],adjust_unknowns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the most frequent words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=sorted(mylm.unigram.items(),key=lambda x:x[1],reverse =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__START', 0.0767994807109772),\n",
       " ('__END', 0.0767994807109772),\n",
       " (',', 0.055092985858456345),\n",
       " ('the', 0.03996174784564508),\n",
       " ('.', 0.03794896863430192),\n",
       " ('of', 0.021419336570876007),\n",
       " ('and', 0.018276622911758262),\n",
       " ('to', 0.01652963206342592),\n",
       " ('a', 0.016050144514074764),\n",
       " ('``', 0.015263464384359356)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the vocabulary?  What kind of words are low frequency?  What kind of words are mid-frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvocab=vocab[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvocab[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you can:\n",
    "* look up bigram probabilities\n",
    "* generate a sentence according to the model\n",
    "* calculate the perplexity of a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0:ADAMB10.TXT\n",
      "Processing file 1:ECORE10.TXT\n",
      "Processing file 2:INDHE10.TXT\n",
      "Processing file 3:GNDIN10.TXT\n",
      "Processing file 4:BBEAU10.TXT\n",
      "Processing file 5:FWALD10.TXT\n",
      "Processing file 6:RCRIM10.TXT\n",
      "Processing file 7:KDNPD10.TXT\n",
      "Processing file 8:SWGEM10.TXT\n",
      "Processing file 9:TSAMU10.TXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "488.57547866385994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylm.compute_perplexity(filenames=testing[:MAX_FILES],methodparams={\"method\":\"bigram\",\"smoothing\":\"kneser-ney\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.compute_perplexity(filenames=testing[:MAX_FILES],methodparams={\"method\":\"bigram\",\"smoothing\":\"absolute\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.compute_perplexity(filenames=testing[:MAX_FILES],methodparams={\"method\":\"unigram\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load in and have a look at the sentence completion challenge questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ly/r2z2fhl14xq43c1wx18pqv840000gn/T/ipykernel_22619/716548752.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd, csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>a)</th>\n",
       "      <th>b)</th>\n",
       "      <th>c)</th>\n",
       "      <th>d)</th>\n",
       "      <th>e)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I have it from the same source that you are bo...</td>\n",
       "      <td>crying</td>\n",
       "      <td>instantaneously</td>\n",
       "      <td>residing</td>\n",
       "      <td>matched</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>It was furnished partly as a sitting and partl...</td>\n",
       "      <td>daintily</td>\n",
       "      <td>privately</td>\n",
       "      <td>inadvertently</td>\n",
       "      <td>miserably</td>\n",
       "      <td>comfortably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>As I descended , my old ally , the _____ , cam...</td>\n",
       "      <td>gods</td>\n",
       "      <td>moon</td>\n",
       "      <td>panther</td>\n",
       "      <td>guard</td>\n",
       "      <td>country-dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We got off , _____ our fare , and the trap rat...</td>\n",
       "      <td>rubbing</td>\n",
       "      <td>doubling</td>\n",
       "      <td>paid</td>\n",
       "      <td>naming</td>\n",
       "      <td>carrying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>He held in his hand a _____ of blue paper , sc...</td>\n",
       "      <td>supply</td>\n",
       "      <td>parcel</td>\n",
       "      <td>sign</td>\n",
       "      <td>sheet</td>\n",
       "      <td>chorus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                           question        a)  \\\n",
       "0  1  I have it from the same source that you are bo...    crying   \n",
       "1  2  It was furnished partly as a sitting and partl...  daintily   \n",
       "2  3  As I descended , my old ally , the _____ , cam...      gods   \n",
       "3  4  We got off , _____ our fare , and the trap rat...   rubbing   \n",
       "4  5  He held in his hand a _____ of blue paper , sc...    supply   \n",
       "\n",
       "                b)             c)         d)             e)  \n",
       "0  instantaneously       residing    matched        walking  \n",
       "1        privately  inadvertently  miserably    comfortably  \n",
       "2             moon        panther      guard  country-dance  \n",
       "3         doubling           paid     naming       carrying  \n",
       "4           parcel           sign      sheet         chorus  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, csv\n",
    "questions=os.path.join(parentdir,\"testing_data.csv\")\n",
    "answers=os.path.join(parentdir,\"test_answer.csv\")\n",
    "\n",
    "with open(questions) as instream:\n",
    "    csvreader=csv.reader(instream)\n",
    "    lines=list(csvreader)\n",
    "qs_df=pd.DataFrame(lines[1:],columns=lines[0])\n",
    "qs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to be able to tokenize questions so that the gaps can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize as tokenize\n",
    "\n",
    "tokens=[tokenize(q) for q in qs_df['question']]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the context of the blank: looking at the preceding words (number given in window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>a)</th>\n",
       "      <th>b)</th>\n",
       "      <th>c)</th>\n",
       "      <th>d)</th>\n",
       "      <th>e)</th>\n",
       "      <th>tokens</th>\n",
       "      <th>left_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I have it from the same source that you are bo...</td>\n",
       "      <td>crying</td>\n",
       "      <td>instantaneously</td>\n",
       "      <td>residing</td>\n",
       "      <td>matched</td>\n",
       "      <td>walking</td>\n",
       "      <td>[I, have, it, from, the, same, source, that, y...</td>\n",
       "      <td>[and, are]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>It was furnished partly as a sitting and partl...</td>\n",
       "      <td>daintily</td>\n",
       "      <td>privately</td>\n",
       "      <td>inadvertently</td>\n",
       "      <td>miserably</td>\n",
       "      <td>comfortably</td>\n",
       "      <td>[It, was, furnished, partly, as, a, sitting, a...</td>\n",
       "      <td>[flowers, arranged]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>As I descended , my old ally , the _____ , cam...</td>\n",
       "      <td>gods</td>\n",
       "      <td>moon</td>\n",
       "      <td>panther</td>\n",
       "      <td>guard</td>\n",
       "      <td>country-dance</td>\n",
       "      <td>[As, I, descended, ,, my, old, ally, ,, the, _...</td>\n",
       "      <td>[,, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We got off , _____ our fare , and the trap rat...</td>\n",
       "      <td>rubbing</td>\n",
       "      <td>doubling</td>\n",
       "      <td>paid</td>\n",
       "      <td>naming</td>\n",
       "      <td>carrying</td>\n",
       "      <td>[We, got, off, ,, _____, our, fare, ,, and, th...</td>\n",
       "      <td>[off, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>He held in his hand a _____ of blue paper , sc...</td>\n",
       "      <td>supply</td>\n",
       "      <td>parcel</td>\n",
       "      <td>sign</td>\n",
       "      <td>sheet</td>\n",
       "      <td>chorus</td>\n",
       "      <td>[He, held, in, his, hand, a, _____, of, blue, ...</td>\n",
       "      <td>[hand, a]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                           question        a)  \\\n",
       "0  1  I have it from the same source that you are bo...    crying   \n",
       "1  2  It was furnished partly as a sitting and partl...  daintily   \n",
       "2  3  As I descended , my old ally , the _____ , cam...      gods   \n",
       "3  4  We got off , _____ our fare , and the trap rat...   rubbing   \n",
       "4  5  He held in his hand a _____ of blue paper , sc...    supply   \n",
       "\n",
       "                b)             c)         d)             e)  \\\n",
       "0  instantaneously       residing    matched        walking   \n",
       "1        privately  inadvertently  miserably    comfortably   \n",
       "2             moon        panther      guard  country-dance   \n",
       "3         doubling           paid     naming       carrying   \n",
       "4           parcel           sign      sheet         chorus   \n",
       "\n",
       "                                              tokens         left_context  \n",
       "0  [I, have, it, from, the, same, source, that, y...           [and, are]  \n",
       "1  [It, was, furnished, partly, as, a, sitting, a...  [flowers, arranged]  \n",
       "2  [As, I, descended, ,, my, old, ally, ,, the, _...             [,, the]  \n",
       "3  [We, got, off, ,, _____, our, fare, ,, and, th...             [off, ,]  \n",
       "4  [He, held, in, his, hand, a, _____, of, blue, ...            [hand, a]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_left_context(sent_tokens,window,target=\"_____\"):\n",
    "    found=-1\n",
    "    for i,token in enumerate(sent_tokens):\n",
    "        if token==target:\n",
    "            found=i\n",
    "            break \n",
    "            \n",
    "    if found>-1:\n",
    "        return sent_tokens[i-window:i]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "qs_df['tokens']=qs_df['question'].map(tokenize)\n",
    "qs_df['left_context']=qs_df['tokens'].map(lambda x: get_left_context(x,2))\n",
    "qs_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building and evaluating an SCC system\n",
    "1. always predict the same answer (e.g., \"a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scc import *\n",
    "### you can import this the above line but I have included the code here to make it easier to inspect it\n",
    "\n",
    "class question:\n",
    "    \n",
    "    def __init__(self,aline):\n",
    "        self.fields=aline\n",
    "    \n",
    "    def get_field(self,field):\n",
    "        return self.fields[question.colnames[field]]\n",
    "    \n",
    "    def add_answer(self,fields):\n",
    "        self.answer=fields[1]\n",
    "   \n",
    "    def chooseA(self):\n",
    "        return(\"a\")\n",
    "\n",
    "    def chooseRandom(self):\n",
    "        return random.choice([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "\n",
    "    def chooseUnigramProb(self):\n",
    "        print (self.fields[1])\n",
    "        return self.get_field(mylm.nextlikely(k=1, current=self.fields[1], method=\"unigram\")), \"a\"\n",
    "        \n",
    "    \n",
    "    def predict(self,method=\"chooseA\"):\n",
    "        #eventually there will be lots of methods to choose from\n",
    "        if method==\"chooseA\":\n",
    "            return self.chooseA()\n",
    "        if method==\"chooseRandom\":\n",
    "            return self.chooseRandom()\n",
    "        if method==\"chooseUnigramProb\":\n",
    "            return self.chooseUnigramProb()\n",
    "        \n",
    "    def predict_and_score(self,method=\"chooseA\"):\n",
    "        \n",
    "        #compare prediction according to method with the correct answer\n",
    "        #return 1 or 0 accordingly\n",
    "        prediction=self.predict(method=method)\n",
    "        #print(prediction, self.answer)\n",
    "        if prediction ==self.answer:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class scc_reader:\n",
    "    \n",
    "    def __init__(self,qs=questions,ans=answers):\n",
    "        self.qs=qs\n",
    "        self.ans=ans\n",
    "        self.read_files()\n",
    "        \n",
    "    def read_files(self):\n",
    "        \n",
    "        #read in the question file\n",
    "        with open(self.qs) as instream:\n",
    "            csvreader=csv.reader(instream)\n",
    "            qlines=list(csvreader)\n",
    "        \n",
    "        #store the column names as a reverse index so they can be used to reference parts of the question\n",
    "        question.colnames={item:i for i,item in enumerate(qlines[0])}\n",
    "        \n",
    "        #create a question instance for each line of the file (other than heading line)\n",
    "        self.questions=[question(qline) for qline in qlines[1:]]\n",
    "        \n",
    "        #read in the answer file\n",
    "        with open(self.ans) as instream:\n",
    "            csvreader=csv.reader(instream)\n",
    "            alines=list(csvreader)\n",
    "            \n",
    "        #add answers to questions so predictions can be checked    \n",
    "        for q,aline in zip(self.questions,alines[1:]):\n",
    "            q.add_answer(aline)\n",
    "        \n",
    "    def get_field(self,field):\n",
    "        return [q.get_field(field) for q in self.questions] \n",
    "    \n",
    "    def predict(self,method=\"chooseA\"):\n",
    "        return [q.predict(method=method) for q in self.questions]\n",
    "    \n",
    "    def predict_and_score(self,method=\"chooseA\"):\n",
    "        scores=[q.predict_and_score(method=method) for q in self.questions]\n",
    "        return sum(scores)/len(scores)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC = scc_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instantaneously',\n",
       " 'privately',\n",
       " 'moon',\n",
       " 'doubling',\n",
       " 'parcel',\n",
       " 'stick',\n",
       " 'communication',\n",
       " 'speedy',\n",
       " 'farmhouse',\n",
       " 'intermittently',\n",
       " 'begged',\n",
       " 'stars',\n",
       " 'delicate',\n",
       " 'cheers',\n",
       " 'advocate',\n",
       " 'prospect',\n",
       " 'accustomed',\n",
       " 'dared',\n",
       " 'moonlight',\n",
       " 'meditation',\n",
       " 'weak',\n",
       " 'touched',\n",
       " 'seamanship',\n",
       " 'affairs',\n",
       " 'wayside',\n",
       " 'knocker',\n",
       " 'darkly',\n",
       " 'inevitable',\n",
       " 'glanced',\n",
       " 'abilities',\n",
       " 'confirmed',\n",
       " 'misfortunes',\n",
       " 'shadow',\n",
       " 'marched',\n",
       " 'universities',\n",
       " 'pedantic',\n",
       " 'backed',\n",
       " 'varnish',\n",
       " 'stripped',\n",
       " 'mellowed',\n",
       " 'control',\n",
       " 'resolution',\n",
       " 'correspondence',\n",
       " 'ride',\n",
       " 'choose',\n",
       " 'note',\n",
       " 'encumbered',\n",
       " 'affliction',\n",
       " 'dirty',\n",
       " 'smiling',\n",
       " 'running',\n",
       " 'surrounded',\n",
       " 'message',\n",
       " 'childish',\n",
       " 'folded',\n",
       " 'translated',\n",
       " 'tired',\n",
       " 'softened',\n",
       " 'slouched',\n",
       " 'matters',\n",
       " 'related',\n",
       " 'chamber',\n",
       " 'struggle',\n",
       " 'smiled',\n",
       " 'realised',\n",
       " 'explain',\n",
       " 'thicket',\n",
       " 'weather',\n",
       " 'saints',\n",
       " 'devil',\n",
       " 'bent',\n",
       " 'muddle',\n",
       " 'contradict',\n",
       " 'sword',\n",
       " 'pleasantries',\n",
       " 'indirect',\n",
       " 'loud',\n",
       " 'parties',\n",
       " 'peace',\n",
       " 'enjoyed',\n",
       " 'rolling',\n",
       " 'numerous',\n",
       " 'sleeping',\n",
       " 'suspected',\n",
       " 'fling',\n",
       " 'convinced',\n",
       " 'relics',\n",
       " 'awaited',\n",
       " 'healed',\n",
       " 'porch',\n",
       " 'startled',\n",
       " 'sandwiches',\n",
       " 'detach',\n",
       " 'client',\n",
       " 'clatter',\n",
       " 'considered',\n",
       " 'picturesque',\n",
       " 'baked',\n",
       " 'fish',\n",
       " 'lies',\n",
       " 'arose',\n",
       " 'cautioning',\n",
       " 'descendants',\n",
       " 'sitting-room',\n",
       " 'marvelling',\n",
       " 'strike',\n",
       " 'humming',\n",
       " 'delivered',\n",
       " 'ends',\n",
       " 'cloth',\n",
       " 'reseated',\n",
       " 'withered',\n",
       " 'revolution',\n",
       " 'logs',\n",
       " 'actions',\n",
       " 'race',\n",
       " 'persuade',\n",
       " 'gush',\n",
       " 'submitted',\n",
       " 'cane',\n",
       " 'superstitious',\n",
       " 'actor',\n",
       " 'published',\n",
       " 'leaned',\n",
       " 'cultivate',\n",
       " 'join',\n",
       " 'thankful',\n",
       " 'warm',\n",
       " 'hanging',\n",
       " 'actress',\n",
       " 'reward',\n",
       " 'friendship',\n",
       " 'sepulchre',\n",
       " 'luck',\n",
       " 'fishes',\n",
       " 'imagine',\n",
       " 'madman',\n",
       " 'sunset',\n",
       " 'unprofitable',\n",
       " 'pencil',\n",
       " 'executrix',\n",
       " 'caste',\n",
       " 'couple',\n",
       " 'fame',\n",
       " 'substantial',\n",
       " 'professional',\n",
       " 'thin',\n",
       " 'knife',\n",
       " 'safe',\n",
       " 'abroad',\n",
       " 'blocked',\n",
       " 'bacon',\n",
       " 'workers',\n",
       " 'bandage',\n",
       " 'gain',\n",
       " 'offence',\n",
       " 'drawing-room',\n",
       " 'lie',\n",
       " 'pawned',\n",
       " 'wakes',\n",
       " 'opposite',\n",
       " 'torrent',\n",
       " 'banished',\n",
       " 'shame',\n",
       " 'mangled',\n",
       " 'possesses',\n",
       " 'dangerous',\n",
       " 'dash',\n",
       " 'pistol',\n",
       " 'clerks',\n",
       " 'retaining',\n",
       " 'undo',\n",
       " 'concluded',\n",
       " 'breeze',\n",
       " 'goes',\n",
       " 'burn',\n",
       " 'slain',\n",
       " 'degrees',\n",
       " 'books',\n",
       " 'quartered',\n",
       " 'increase',\n",
       " 'hesitation',\n",
       " 'twisted',\n",
       " 'dying',\n",
       " 'lengths',\n",
       " 'losers',\n",
       " 'reign',\n",
       " 'waded',\n",
       " 'slept',\n",
       " 'reckless',\n",
       " 'acquaintance',\n",
       " 'pity',\n",
       " 'indifference',\n",
       " 'interested',\n",
       " 'aware',\n",
       " 'proudest',\n",
       " 'coward',\n",
       " 'follow',\n",
       " 'petty',\n",
       " 'dispatched',\n",
       " 'beauty',\n",
       " 'shouted',\n",
       " 'negotiations',\n",
       " 'acuteness',\n",
       " 'closing',\n",
       " 'refuse',\n",
       " 'arguments',\n",
       " 'revealing',\n",
       " 'flags',\n",
       " 'obstacles',\n",
       " 'satisfy',\n",
       " 'ruffled',\n",
       " 'bamboos',\n",
       " 'glittered',\n",
       " 'wicker-work',\n",
       " 'thrill',\n",
       " 'ordered',\n",
       " 'humdrum',\n",
       " 'aspect',\n",
       " 'matches',\n",
       " 'dangerous',\n",
       " 'impudence',\n",
       " 'singing',\n",
       " 'aeroplane',\n",
       " 'dumfounded',\n",
       " 'bravery',\n",
       " 'weep',\n",
       " 'bosom',\n",
       " 'kicking',\n",
       " 'horror-stricken',\n",
       " 'horror',\n",
       " 'variety',\n",
       " 'tints',\n",
       " 'listening',\n",
       " 'aristocrat',\n",
       " 'permitted',\n",
       " 'whiskers',\n",
       " 'stepped',\n",
       " 'inquest',\n",
       " 'staff',\n",
       " 'exhortations',\n",
       " 'sneered',\n",
       " 'circumstances',\n",
       " 'invoked',\n",
       " 'whirled',\n",
       " 'impossible',\n",
       " 'prevent',\n",
       " 'prolong',\n",
       " 'pistol',\n",
       " 'faith',\n",
       " 'breakfasted',\n",
       " 'magical',\n",
       " 'eased',\n",
       " 'astray',\n",
       " 'veil',\n",
       " 'finding',\n",
       " 'prompt',\n",
       " 'training',\n",
       " 'recklessness',\n",
       " 'deliberate',\n",
       " 'sixteen',\n",
       " 'compared',\n",
       " 'absolute',\n",
       " 'producing',\n",
       " 'news',\n",
       " 'lives',\n",
       " 'contest',\n",
       " 'kindly',\n",
       " 'packages',\n",
       " 'contrary',\n",
       " 'cheap',\n",
       " 'poisoned',\n",
       " 'sagacity',\n",
       " 'tilting',\n",
       " 'government',\n",
       " 'contrast',\n",
       " 'consulting-room',\n",
       " 'falling',\n",
       " 'agree',\n",
       " 'planned',\n",
       " 'notion',\n",
       " 'uptown',\n",
       " 'sending',\n",
       " 'oaks',\n",
       " 'apologies',\n",
       " 'knight',\n",
       " 'parents',\n",
       " 'quick',\n",
       " 'awakened',\n",
       " 'nowhere',\n",
       " 'arose',\n",
       " 'provided',\n",
       " 'mere',\n",
       " 'massive',\n",
       " 'fate',\n",
       " 'pictures',\n",
       " 'girlish',\n",
       " 'carriage',\n",
       " 'fatal',\n",
       " 'problem',\n",
       " 'abhor',\n",
       " 'propagated',\n",
       " 'performed',\n",
       " 'quarter',\n",
       " 'kiss',\n",
       " 'eat',\n",
       " 'bowed',\n",
       " 'widened',\n",
       " 'engaging',\n",
       " 'relieved',\n",
       " 'stirred',\n",
       " 'job',\n",
       " 'compass',\n",
       " 'liked',\n",
       " 'sing',\n",
       " 'indifference',\n",
       " 'bunches',\n",
       " 'debate',\n",
       " 'spoils',\n",
       " 'signs',\n",
       " 'lass',\n",
       " 'witch',\n",
       " 'agent',\n",
       " 'livelihood',\n",
       " 'clearest',\n",
       " 'floundered',\n",
       " 'dispute',\n",
       " 'boiled',\n",
       " 'peered',\n",
       " 'questions',\n",
       " 'offensive',\n",
       " 'mocking',\n",
       " 'gray',\n",
       " 'thwarted',\n",
       " 'concealment',\n",
       " 'hole',\n",
       " 'waiter',\n",
       " 'repeat',\n",
       " 'senses',\n",
       " 'resemble',\n",
       " 'limited',\n",
       " 'billiard-room',\n",
       " 'object',\n",
       " 'resources',\n",
       " 'studying',\n",
       " 'bosom',\n",
       " 'carrying',\n",
       " 'stirred',\n",
       " 'wore',\n",
       " 'astonished',\n",
       " 'granted',\n",
       " 'strolling',\n",
       " 'wound',\n",
       " 'winter',\n",
       " 'attack',\n",
       " 'throne',\n",
       " 'shape',\n",
       " 'lose',\n",
       " 'shave',\n",
       " 'hung',\n",
       " 'drunk',\n",
       " 'combined',\n",
       " 'stairs',\n",
       " 'ventured',\n",
       " 'propose',\n",
       " 'earthquake',\n",
       " 'danced',\n",
       " 'enemy',\n",
       " 'crest',\n",
       " 'nurtured',\n",
       " 'sublime',\n",
       " 'residue',\n",
       " 'inborn',\n",
       " 'join',\n",
       " 'gentle',\n",
       " 'hoped',\n",
       " 'reflected',\n",
       " 'faded',\n",
       " 'permission',\n",
       " 'driven',\n",
       " 'faculties',\n",
       " 'passing',\n",
       " 'actual',\n",
       " 'architecture',\n",
       " 'smell',\n",
       " 'divided',\n",
       " 'convocation',\n",
       " 'sadder',\n",
       " 'splitting',\n",
       " 'picture',\n",
       " 'contemplate',\n",
       " 'historical',\n",
       " 'handsome',\n",
       " 'mighty',\n",
       " 'entertainment',\n",
       " 'lonely',\n",
       " 'asleep',\n",
       " 'luminous',\n",
       " 'calm',\n",
       " 'ocean',\n",
       " 'shape',\n",
       " 'kindled',\n",
       " 'guards',\n",
       " 'seven',\n",
       " 'learning',\n",
       " 'commands',\n",
       " 'hounded',\n",
       " 'misfortune',\n",
       " 'dreading',\n",
       " 'brain',\n",
       " 'dimpled',\n",
       " 'edge',\n",
       " 'spoken',\n",
       " 'farms',\n",
       " 'comply',\n",
       " 'attended',\n",
       " 'hailed',\n",
       " 'alive',\n",
       " 'nights',\n",
       " 'battalion',\n",
       " 'unseen',\n",
       " 'troubled',\n",
       " 'collar',\n",
       " 'loves',\n",
       " 'breakfast',\n",
       " 'imperious',\n",
       " 'fellowship',\n",
       " 'contour',\n",
       " 'fortunate',\n",
       " 'style',\n",
       " 'splinters',\n",
       " 'object',\n",
       " 'resided',\n",
       " 'damaged',\n",
       " 'mouthful',\n",
       " 'senseless',\n",
       " 'stroke',\n",
       " 'fit',\n",
       " 'wickedly',\n",
       " 'glowering',\n",
       " 'occur',\n",
       " 'running',\n",
       " 'hurling',\n",
       " 'flavor',\n",
       " 'earthquake',\n",
       " 'touched',\n",
       " 'wicked',\n",
       " 'increase',\n",
       " 'dismissed',\n",
       " 'degree',\n",
       " 'policeman',\n",
       " 'oranges',\n",
       " 'watching',\n",
       " 'cases',\n",
       " 'orchids',\n",
       " 'lists',\n",
       " 'cliffs',\n",
       " 'dressed',\n",
       " 'carry',\n",
       " 'motionless',\n",
       " 'sky',\n",
       " 'ancestry',\n",
       " 'passage',\n",
       " 'envelope',\n",
       " 'groans',\n",
       " 'renounced',\n",
       " 'surround',\n",
       " 'staggering',\n",
       " 'shyness',\n",
       " 'disappointment',\n",
       " 'shape',\n",
       " 'kings',\n",
       " 'collective',\n",
       " 'sinking',\n",
       " 'effigy',\n",
       " 'charmed',\n",
       " 'mannerism',\n",
       " 'reluctance',\n",
       " 'satisfied',\n",
       " 'yard',\n",
       " 'reminded',\n",
       " 'surveying',\n",
       " 'rowers',\n",
       " 'circumstance',\n",
       " 'underestimate',\n",
       " 'swim',\n",
       " 'entrusted',\n",
       " 'slept',\n",
       " 'ridiculous',\n",
       " 'row',\n",
       " 'client',\n",
       " 'translate',\n",
       " 'studied',\n",
       " 'closing',\n",
       " 'shelterless',\n",
       " 'heaven',\n",
       " 'instincts',\n",
       " 'kiss',\n",
       " 'shouted',\n",
       " 'unaccustomed',\n",
       " 'blessing',\n",
       " 'umbrella',\n",
       " 'drive',\n",
       " 'spotted',\n",
       " 'glint',\n",
       " 'relations',\n",
       " 'mingled',\n",
       " 'gently',\n",
       " 'trod',\n",
       " 'complexion',\n",
       " 'vanished',\n",
       " 'misfortune',\n",
       " 'walking',\n",
       " 'impending',\n",
       " 'tired',\n",
       " 'impossible',\n",
       " 'wagon',\n",
       " 'tonight',\n",
       " 'expended',\n",
       " 'impressed',\n",
       " 'civic',\n",
       " 'bell',\n",
       " 'crouched',\n",
       " 'angels',\n",
       " 'warmth',\n",
       " 'disgrace',\n",
       " 'divided',\n",
       " 'mitigate',\n",
       " 'impression',\n",
       " 'using',\n",
       " 'slight',\n",
       " 'pale',\n",
       " 'orchards',\n",
       " 'opening',\n",
       " \"lady's\",\n",
       " 'vanished',\n",
       " 'revolution',\n",
       " 'conscience',\n",
       " 'secure',\n",
       " 'passage',\n",
       " 'reflected',\n",
       " 'shut',\n",
       " 'creek',\n",
       " 'hurrying',\n",
       " 'destroyed',\n",
       " 'reading',\n",
       " 'mirror',\n",
       " 'ticket',\n",
       " 'marvellous',\n",
       " 'yellow',\n",
       " 'caused',\n",
       " 'quarreled',\n",
       " 'irony',\n",
       " 'interpreter',\n",
       " 'appraised',\n",
       " 'sank',\n",
       " 'smell',\n",
       " 'trial',\n",
       " 'commanded',\n",
       " 'inform',\n",
       " 'emaciated',\n",
       " 'touched',\n",
       " 'hitching',\n",
       " 'faced',\n",
       " 'contribute',\n",
       " 'quarrel',\n",
       " 'ransacked',\n",
       " 'clothing',\n",
       " 'furnished',\n",
       " 'appetites',\n",
       " 'boats',\n",
       " 'likely',\n",
       " 'glance',\n",
       " 'ribbon',\n",
       " 'reins',\n",
       " 'promise',\n",
       " 'disabled',\n",
       " 'imprudence',\n",
       " 'anticipated',\n",
       " 'interested',\n",
       " 'danger',\n",
       " 'salutary',\n",
       " 'shutters',\n",
       " 'impulse',\n",
       " 'forget',\n",
       " 'animals',\n",
       " 'hurried',\n",
       " 'move',\n",
       " 'address',\n",
       " 'lord',\n",
       " 'ambiguity',\n",
       " 'useful',\n",
       " 'symbol',\n",
       " 'idle',\n",
       " 'nations',\n",
       " 'befall',\n",
       " 'couch',\n",
       " 'intention',\n",
       " 'bulk',\n",
       " 'cord',\n",
       " 'glossy',\n",
       " 'darker',\n",
       " 'thunders',\n",
       " 'spent',\n",
       " 'imagine',\n",
       " 'prosper',\n",
       " 'jug',\n",
       " 'tail',\n",
       " 'conquer',\n",
       " 'whisked',\n",
       " 'desirable',\n",
       " 'advocate',\n",
       " 'burning',\n",
       " 'drawn',\n",
       " 'compromise',\n",
       " 'passengers',\n",
       " 'lift',\n",
       " 'engineers',\n",
       " 'sheathed',\n",
       " 'cardboard',\n",
       " 'economical',\n",
       " 'clouds',\n",
       " 'leaped',\n",
       " 'follow',\n",
       " 'examination',\n",
       " 'sturdy',\n",
       " 'deception',\n",
       " 'apparition',\n",
       " 'intolerable',\n",
       " 'jolting',\n",
       " 'wiggle',\n",
       " 'books',\n",
       " 'paused',\n",
       " 'battle',\n",
       " 'talked',\n",
       " 'accepting',\n",
       " 'footprints',\n",
       " 'grasped',\n",
       " 'wrung',\n",
       " 'history',\n",
       " 'decided',\n",
       " 'spoken',\n",
       " 'disobey',\n",
       " 'watching',\n",
       " 'villa',\n",
       " 'Athenian',\n",
       " 'paid',\n",
       " 'sustain',\n",
       " 'heaped',\n",
       " 'painting',\n",
       " 'reply',\n",
       " 'knocked',\n",
       " 'screamed',\n",
       " 'poetry',\n",
       " 'skin',\n",
       " 'blowing',\n",
       " 'volume',\n",
       " 'hoisting',\n",
       " 'wrapped',\n",
       " 'comforter',\n",
       " 'deplored',\n",
       " 'buildings',\n",
       " 'waited',\n",
       " 'offer',\n",
       " 'tenderness',\n",
       " 'oppressed',\n",
       " 'offered',\n",
       " 'stumped',\n",
       " 'mightier',\n",
       " 'tall',\n",
       " 'discretion',\n",
       " 'midway',\n",
       " 'semicircle',\n",
       " 'emperor',\n",
       " 'results',\n",
       " 'Bombay',\n",
       " 'interval',\n",
       " 'refusing',\n",
       " 'throw',\n",
       " 'clue',\n",
       " 'yelled',\n",
       " 'wrote',\n",
       " 'assured',\n",
       " 'crack',\n",
       " 'climbed',\n",
       " 'curiosity',\n",
       " 'ample',\n",
       " 'preventing',\n",
       " 'showing',\n",
       " 'pity',\n",
       " 'spent',\n",
       " 'smell',\n",
       " 'strayed',\n",
       " 'moon',\n",
       " 'exception',\n",
       " 'contended',\n",
       " 'crafty',\n",
       " 'labours',\n",
       " 'privacy',\n",
       " 'yards',\n",
       " 'destroy',\n",
       " 'departure',\n",
       " 'interests',\n",
       " 'bottom',\n",
       " 'plains',\n",
       " 'paced',\n",
       " 'yard',\n",
       " 'iron',\n",
       " 'blackest',\n",
       " 'thumping',\n",
       " 'successful',\n",
       " 'dispel',\n",
       " 'prove',\n",
       " 'list',\n",
       " 'explanation',\n",
       " 'pace',\n",
       " 'spectacular',\n",
       " 'ascending',\n",
       " 'scientific',\n",
       " 'impatient',\n",
       " 'shrewd',\n",
       " 'admirable',\n",
       " 'encircled',\n",
       " 'constrained',\n",
       " 'commonplace',\n",
       " 'peered',\n",
       " 'consumed',\n",
       " 'opprobrium',\n",
       " 'health',\n",
       " 'breathless',\n",
       " 'ingenious',\n",
       " 'papers',\n",
       " 'shunning',\n",
       " 'contemptuous',\n",
       " 'gay',\n",
       " 'cushioned',\n",
       " 'hall',\n",
       " 'stages',\n",
       " 'devoured',\n",
       " 'travelling',\n",
       " 'wrote',\n",
       " 'headgear',\n",
       " 'telegraph',\n",
       " 'canoe',\n",
       " 'ravage',\n",
       " 'individuals',\n",
       " 'opportunity',\n",
       " 'mountain',\n",
       " 'guarded',\n",
       " 'attentive',\n",
       " 'rivers',\n",
       " 'apportioned',\n",
       " 'ordered',\n",
       " 'dangerous',\n",
       " 'repast',\n",
       " 'dislodged',\n",
       " 'clouded',\n",
       " 'lamp',\n",
       " 'hardened',\n",
       " 'rude',\n",
       " 'marry',\n",
       " 'sweet',\n",
       " 'interpreter',\n",
       " 'sign',\n",
       " 'powerful',\n",
       " 'ordinarily',\n",
       " 'sold',\n",
       " 'swept',\n",
       " 'consult',\n",
       " 'highways',\n",
       " 'mechanism',\n",
       " 'staring',\n",
       " 'admit',\n",
       " 'trap',\n",
       " 'box',\n",
       " 'pulpit',\n",
       " 'easiest',\n",
       " 'pompous',\n",
       " 'listening',\n",
       " 'preserve',\n",
       " 'wine',\n",
       " 'written',\n",
       " 'assigned',\n",
       " 'clad',\n",
       " 'disappeared',\n",
       " 'honoured',\n",
       " 'enemy',\n",
       " 'separate',\n",
       " 'Museum',\n",
       " 'warm',\n",
       " 'flourished',\n",
       " 'porch',\n",
       " 'summer',\n",
       " 'revolver',\n",
       " 'pale',\n",
       " 'clearly',\n",
       " 'yielded',\n",
       " 'refuges',\n",
       " 'window-sill',\n",
       " 'spoken',\n",
       " 'persecution',\n",
       " 'chances',\n",
       " 'exhibition',\n",
       " 'wonderful',\n",
       " 'size',\n",
       " 'empty',\n",
       " 'crawling',\n",
       " 'wine',\n",
       " 'promptly',\n",
       " 'swarmed',\n",
       " 'warm',\n",
       " 'insulted',\n",
       " 'purple',\n",
       " 'nerveless',\n",
       " 'nobly',\n",
       " 'tempestuous',\n",
       " 'apron',\n",
       " 'quietly',\n",
       " 'lead',\n",
       " 'log',\n",
       " 'field',\n",
       " 'tender',\n",
       " 'remembrance',\n",
       " 'forgotten',\n",
       " 'handkerchief',\n",
       " 'cook',\n",
       " 'resolution',\n",
       " 'curry',\n",
       " 'train',\n",
       " 'milk',\n",
       " 'correctly',\n",
       " 'count',\n",
       " 'trip',\n",
       " 'dropped',\n",
       " 'guinea',\n",
       " 'tempo',\n",
       " 'saddle',\n",
       " 'medical',\n",
       " 'reappeared',\n",
       " 'proudly',\n",
       " 'toys',\n",
       " 'design',\n",
       " 'imitate',\n",
       " 'conversation',\n",
       " 'investigation',\n",
       " 'imaginary',\n",
       " 'store-room',\n",
       " 'operations',\n",
       " 'good-night',\n",
       " 'solitude',\n",
       " 'narrow',\n",
       " 'assisted',\n",
       " 'wrung',\n",
       " 'force',\n",
       " 'born',\n",
       " 'luncheon-table',\n",
       " 'noticed',\n",
       " 'arrested',\n",
       " 'denomination',\n",
       " 'anecdote',\n",
       " 'shadow',\n",
       " 'barely',\n",
       " 'wasted',\n",
       " 'finished',\n",
       " 'separated',\n",
       " 'blow',\n",
       " 'emerged',\n",
       " \"mother's\",\n",
       " 'courage',\n",
       " 'taught',\n",
       " 'unkindness',\n",
       " 'humming',\n",
       " 'mere',\n",
       " 'gather',\n",
       " 'refreshing',\n",
       " 'wildly',\n",
       " 'fence',\n",
       " 'cage',\n",
       " 'remarked',\n",
       " 'remove',\n",
       " 'lurched',\n",
       " 'defiantly',\n",
       " 'design',\n",
       " 'pamphlet',\n",
       " 'support',\n",
       " 'ice',\n",
       " 'cease',\n",
       " 'withered',\n",
       " 'wandering',\n",
       " 'choose',\n",
       " 'blind',\n",
       " 'breakfast',\n",
       " 'assistant',\n",
       " 'map',\n",
       " 'inexorable',\n",
       " 'apart',\n",
       " 'asking',\n",
       " 'drawn',\n",
       " 'spent',\n",
       " 'incisive',\n",
       " 'falling',\n",
       " 'godmother',\n",
       " 'charged',\n",
       " 'wood',\n",
       " 'charming',\n",
       " 'lifetime',\n",
       " 'fitted',\n",
       " 'destined',\n",
       " 'gripped',\n",
       " 'terrible',\n",
       " 'daring',\n",
       " 'garments',\n",
       " 'resounded',\n",
       " 'deserted',\n",
       " 'arched',\n",
       " 'verify',\n",
       " 'absolute',\n",
       " 'burn',\n",
       " 'reveal',\n",
       " 'capable',\n",
       " 'sprang',\n",
       " 'glared',\n",
       " 'angry',\n",
       " 'wretchedness',\n",
       " 'hers',\n",
       " 'curled',\n",
       " 'morrow',\n",
       " 'gathered',\n",
       " 'sunset',\n",
       " 'excuses',\n",
       " 'fables',\n",
       " 'lounging',\n",
       " 'delay',\n",
       " 'verge',\n",
       " 'bucket',\n",
       " 'dictated',\n",
       " \"everybody's\",\n",
       " 'astonishment',\n",
       " 'seven',\n",
       " 'rolled',\n",
       " 'dissipated',\n",
       " 'cat',\n",
       " 'concluded',\n",
       " 'desires',\n",
       " 'primitive',\n",
       " 'written',\n",
       " 'fed',\n",
       " 'influence',\n",
       " 'crept',\n",
       " 'eaten',\n",
       " 'closet',\n",
       " 'discontent',\n",
       " 'bag',\n",
       " 'breakfast',\n",
       " 'burst',\n",
       " 'rotted',\n",
       " 'reward',\n",
       " 'star',\n",
       " 'examined',\n",
       " 'humble',\n",
       " 'freshly',\n",
       " 'realize',\n",
       " 'grasp',\n",
       " 'owed',\n",
       " 'touched',\n",
       " 'twice',\n",
       " 'asylum',\n",
       " 'fixed',\n",
       " 'cast',\n",
       " 'surprised',\n",
       " 'lunched',\n",
       " 'devil',\n",
       " 'hill',\n",
       " 'herring',\n",
       " 'barracks',\n",
       " 'breathe',\n",
       " 'gardener',\n",
       " 'hunger',\n",
       " 'accompany',\n",
       " 'temporary',\n",
       " 'anyone',\n",
       " 'faced',\n",
       " 'mathematical',\n",
       " 'theory',\n",
       " 'weary',\n",
       " 'gang',\n",
       " 'belief',\n",
       " 'excitement',\n",
       " 'mortal',\n",
       " 'averse',\n",
       " 'explanation',\n",
       " 'drowsy',\n",
       " 'sleeping',\n",
       " 'ambitious',\n",
       " 'leaped',\n",
       " 'flash',\n",
       " 'meddle',\n",
       " 'hutch',\n",
       " 'infirm',\n",
       " 'kiss',\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCC.get_field(\"b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " ...]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCC.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19903846153846153"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCC.predict_and_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a random choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC.predict(method=\"chooseRandom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20961538461538462"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCC.predict_and_score(method=\"chooseRandom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the language model\n",
    "using unigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have it from the same source that you are both an orphan and a bachelor and are _____ alone in London.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'__END'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSCC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchooseUnigramProb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[116], line 79\u001b[0m, in \u001b[0;36mscc_reader.predict\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchooseA\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [q\u001b[38;5;241m.\u001b[39mpredict(method\u001b[38;5;241m=\u001b[39mmethod) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions]\n",
      "Cell \u001b[0;32mIn[116], line 79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchooseA\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions]\n",
      "Cell \u001b[0;32mIn[116], line 33\u001b[0m, in \u001b[0;36mquestion.predict\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchooseRandom()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchooseUnigramProb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchooseUnigramProb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[116], line 23\u001b[0m, in \u001b[0;36mquestion.chooseUnigramProb\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchooseUnigramProb\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmylm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnextlikely\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munigram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[116], line 10\u001b[0m, in \u001b[0;36mquestion.get_field\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m,field):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields[\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: '__END'"
     ]
    }
   ],
   "source": [
    "SCC.predict(method=\"chooseUnigramProb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Context\n",
    "looking up context and bigram probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backing off to unigram probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backing off might not change the decision (the correct answer may not be in the bestchoices given back by the bigram model)\n",
    "\n",
    "Investigate: \n",
    "* the effect of the amount of training data on each of the strategies\n",
    "* plot on a graph - should see a cross-over (unigram than bigram for small training data but bigram better than unigram for large training data)\n",
    "\n",
    "Extend:\n",
    "* trigram model\n",
    "* incorporation of distributional similarity / word2vec vectors\n",
    "* RNNLM ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e993f6b24e6dadc761550f81b5ca4f85f65c4625eb1dc51cfa1e968282de6f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
